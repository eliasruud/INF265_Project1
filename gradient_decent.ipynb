{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "torch.manual_seed(265)                  # Sets the randomness\n",
    "torch.set_default_dtype(torch.double)   # Sets the default datatype for tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                          #converts to tensor\n",
    "    transforms.Lambda(lambda x: torch.flatten(x))   #Flattens the tensor\n",
    "])\n",
    "\n",
    "# Loads the cifar10 training and test sets. It downloads it into the data folder and is transformed into a tenser using the transfrom.toTensor.\n",
    "full_train_val_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "full_test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits training set into training and validation set\n",
    "training_size = int(len(full_train_val_set)*0.9)\n",
    "validation_size = len(full_train_val_set) - training_size\n",
    "\n",
    "full_train_set, full_val_set = random_split(full_train_val_set, [training_size, validation_size], generator=torch.Generator().manual_seed(265))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "\n",
    "# Filters out the nonrelevant labels. Keeps the airplane and birds\n",
    "train_set = [(img, label_map[label]) for img, label in full_train_set if label in [0, 2]]\n",
    "test_set = [(img, label_map[label]) for img, label in full_test_set if label in [0, 2]]\n",
    "val_set = [(img, label_map[label]) for img, label in full_val_set if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP class for 3.1.2\n",
    "\n",
    "# CRITERIA:\n",
    "#   * The input dimension is 3072 (= 32*32*3) and the output dimension is 2 (for the 2 classes).\n",
    "#   * The hidden layers have respectively 512, 128 and 32 hidden units.\n",
    "#   * All activation functions are ReLU. The last layer has no activation function since the cross-entropy loss already includes a softmax activation function.\n",
    "\n",
    "# Layout: [3072, 512, 128, 32, 2]\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() # Initializes the nn.module\n",
    "\n",
    "        # Defines the network using seqential.\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=3072, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input): #Passes the input trough the network and returns the output\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #Sets the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        batch_amount = len(train_loader)\n",
    "\n",
    "        for x, y_true  in train_loader:\n",
    "            x, y_true = x.to(device, dtype=torch.double), y_true.to(device)\n",
    "\n",
    "            optimizer.zero_grad()           # Resets the gradients\n",
    "\n",
    "            y_pred = model(x)               # Forward passes the batch\n",
    "\n",
    "            loss = loss_fn(y_pred, y_true)  # calcs the loss\n",
    "            total_loss += loss.item()       # Adds the loss to the total\n",
    "\n",
    "            loss.backward()                 # Backward propogation\n",
    "            optimizer.step()                # Updates the weights and biases\n",
    "\n",
    "        print(\"Train ||| Epoch: \",(i+1), \" of \", n_epochs, \"| Average Loss: \", total_loss / batch_amount)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_manual_update(n_epochs, lr, model, loss_fn, train_loader, weight_decay=0, momentum=0):\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    velocities = {p: torch.zeros_like(p) for p in model.parameters()}\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        batch_amount = len(train_loader)\n",
    "\n",
    "        for x, y_true  in train_loader:\n",
    "            x, y_true = x.to(device, dtype=torch.double), y_true.to(device)\n",
    "            \n",
    "            model.zero_grad()           # Resets the gradients\n",
    "\n",
    "            y_pred = model(x)               # Forward passes the batch\n",
    "\n",
    "            loss = loss_fn(y_pred, y_true)  # calcs the loss\n",
    "            total_loss += loss.item()       # Adds the loss to the total\n",
    "            \n",
    "\n",
    "            loss.backward()                 # Backward propogation\n",
    "            \n",
    "            with torch.no_grad():           #Manually uses gradient decent to update each oarameter\n",
    "                for p, velocity in model.parameters(), velocities.values():\n",
    "                    if p.requires_grad:  # Only update parameters that require gradient\n",
    "\n",
    "                        if momentum != 0:\n",
    "                            grad = p.grad + weight_decay * p\n",
    "                            # Update velocity\n",
    "                            velocity *= momentum\n",
    "                            velocity += grad*lr\n",
    "\n",
    "                            p -= velocity\n",
    "\n",
    "                        else:\n",
    "                            p -= lr*( p.grad + p*weight_decay)     # Equation (2) in project pdf. p = p - lr*p.grad\n",
    "                            \n",
    "\n",
    "        print(\"Train_manual_update ||| Epoch: \",(i+1), \" of \", n_epochs, \"| Average Loss: \", total_loss / batch_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ||| Epoch:  1  of  10 | Average Loss:  0.6759906525975633\n",
      "Train ||| Epoch:  2  of  10 | Average Loss:  0.6193885364965185\n",
      "Train ||| Epoch:  3  of  10 | Average Loss:  0.5490012386761132\n",
      "Train ||| Epoch:  4  of  10 | Average Loss:  0.5200428597277562\n",
      "Train ||| Epoch:  5  of  10 | Average Loss:  0.5085929610671069\n",
      "Train ||| Epoch:  6  of  10 | Average Loss:  0.5012871729824612\n",
      "Train ||| Epoch:  7  of  10 | Average Loss:  0.4952112674215567\n",
      "Train ||| Epoch:  8  of  10 | Average Loss:  0.4896398773165913\n",
      "Train ||| Epoch:  9  of  10 | Average Loss:  0.48401971178514486\n",
      "Train ||| Epoch:  10  of  10 | Average Loss:  0.4784286860893781\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(265)\n",
    "\n",
    "model = MyMLP()\n",
    "\n",
    "lr = 0.01\n",
    "n_epochs = 10\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = DataLoader(train_set, 64)\n",
    "\n",
    "train(n_epochs, optimizer, model, loss_fn, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_manual_update ||| Epoch:  1  of  10 | Average Loss:  0.6969461991856638\n",
      "Train_manual_update ||| Epoch:  2  of  10 | Average Loss:  0.6969461991856638\n",
      "Train_manual_update ||| Epoch:  3  of  10 | Average Loss:  0.6969461991856638\n",
      "Train_manual_update ||| Epoch:  4  of  10 | Average Loss:  0.6969461991856638\n",
      "Train_manual_update ||| Epoch:  5  of  10 | Average Loss:  0.6969461991856638\n",
      "Train_manual_update ||| Epoch:  6  of  10 | Average Loss:  0.6969461991856638\n",
      "Train_manual_update ||| Epoch:  7  of  10 | Average Loss:  0.6969461991856638\n",
      "Train_manual_update ||| Epoch:  8  of  10 | Average Loss:  0.6969461991856638\n",
      "Train_manual_update ||| Epoch:  9  of  10 | Average Loss:  0.6969461991856638\n",
      "Train_manual_update ||| Epoch:  10  of  10 | Average Loss:  0.6969461991856638\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(265)\n",
    "\n",
    "model = MyMLP()\n",
    "\n",
    "lr = 0.01\n",
    "n_epochs = 10\n",
    "weight_decay = 0.5\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = DataLoader(train_set, 64)\n",
    "\n",
    "train_manual_update(n_epochs, lr, model, loss_fn, train_loader, weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JUPYTER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
